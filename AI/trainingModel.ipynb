{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.21.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# =============== 1. Load and Explore the Dataset ===============\n",
    "# Load metadata\n",
    "metadata_path = 'orchids52_metadata-en.txt'\n",
    "class_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metadata_path, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip() != '':\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                class_id = parts[0]\n",
    "                class_name = parts[1]\n",
    "                class_names.append((class_id, class_name))\n",
    "\n",
    "# Create a dictionary mapping class IDs to class names\n",
    "class_dict = {class_id: class_name for class_id, class_name in class_names}\n",
    "print(f\"Total number of classes: {len(class_dict)}\")\n",
    "print(\"First 5 classes:\")\n",
    "for i, (class_id, class_name) in enumerate(class_names[:5]):\n",
    "    print(f\"{class_id}: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get data directories\n",
    "train_dir = 'train-en'\n",
    "test_dir = 'test-en'\n",
    "\n",
    "# Count images in each class\n",
    "train_counts = {}\n",
    "test_counts = {}\n",
    "\n",
    "for class_id in os.listdir(train_dir):\n",
    "    if os.path.isdir(os.path.join(train_dir, class_id)):\n",
    "        train_counts[class_id] = len(os.listdir(os.path.join(train_dir, class_id)))\n",
    "\n",
    "for class_id in os.listdir(test_dir):\n",
    "    if os.path.isdir(os.path.join(test_dir, class_id)):\n",
    "        test_counts[class_id] = len(os.listdir(os.path.join(test_dir, class_id)))\n",
    "\n",
    "# Display some statistics\n",
    "print(f\"Total training images: {sum(train_counts.values())}\")\n",
    "print(f\"Total testing images: {sum(test_counts.values())}\")\n",
    "print(f\"Average images per class (train): {sum(train_counts.values()) / len(train_counts):.1f}\")\n",
    "print(f\"Average images per class (test): {sum(test_counts.values()) / len(test_counts):.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(range(len(train_counts)), list(train_counts.values()))\n",
    "plt.title('Number of Training Images per Class')\n",
    "plt.xlabel('Class Index')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(range(len(train_counts)), list(train_counts.keys()), rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== 2. Visualize Some Sample Images ===============\n",
    "# Display sample images from each class\n",
    "num_classes_to_show = 5\n",
    "images_per_class = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, num_classes_to_show * 3))\n",
    "for i, class_id in enumerate(list(class_dict.keys())[:num_classes_to_show]):\n",
    "    class_dir = os.path.join(train_dir, class_id)\n",
    "    img_files = os.listdir(class_dir)[:images_per_class]\n",
    "    \n",
    "    for j, img_file in enumerate(img_files):\n",
    "        img_path = os.path.join(class_dir, img_file)\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        plt.subplot(num_classes_to_show, images_per_class, i * images_per_class + j + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{class_id}: {class_dict[class_id][:20]}...\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== 3. Create Custom Dataset and DataLoader ===============\n",
    "# Define transforms for training and testing\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create custom dataset class\n",
    "class OrchidDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        self.classes.sort()  # Ensure consistent ordering\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.samples.append((os.path.join(class_dir, img_name), self.class_to_idx[class_name]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = OrchidDataset(train_dir, transform=train_transforms)\n",
    "test_dataset = OrchidDataset(test_dir, transform=test_transforms)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset information\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Testing dataset size: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
    "print(f\"Number of batches (train): {len(train_loader)}\")\n",
    "print(f\"Number of batches (test): {len(test_loader)}\")\n",
    "\n",
    "# =============== 4. Define the Model (Transfer Learning with ResNet50) ===============\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "def get_model(num_classes):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    \n",
    "    # Freeze all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace the final fully connected layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = get_model(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== 5. Training Function ===============\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "        \n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc.item())\n",
    "        \n",
    "        print(f\"[Train] Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        epoch_loss = running_loss / len(test_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(test_dataset)\n",
    "        \n",
    "        history['val_loss'].append(epoch_loss)\n",
    "        history['val_acc'].append(epoch_acc.item())\n",
    "        \n",
    "        print(f\"[Val] Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(epoch_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_acc > best_val_acc:\n",
    "            best_val_acc = epoch_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"Saved new best model with accuracy: {best_val_acc:.4f}\")\n",
    "        \n",
    "        # Print classification report every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(all_labels, all_preds, target_names=[class_dict[cls] for cls in train_dataset.classes]))\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== 6. Train the Model ===============\n",
    "# Train the model\n",
    "num_epochs = 20\n",
    "model, history = train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== 7. Visualize Training Results ===============\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(num_epochs), history['train_loss'], label='Train Loss')\n",
    "plt.plot(range(num_epochs), history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(num_epochs), history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(range(num_epochs), history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== 8. Evaluate on Test Set and Generate Confusion Matrix ===============\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=[class_dict[cls] for cls in train_dataset.classes])\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot confusion matrix (normalized)\n",
    "plt.figure(figsize=(15, 15))\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=False, fmt='.2f', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# =============== 9. Save the Model ===============\n",
    "# Save the model and class mappings\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_to_idx': train_dataset.class_to_idx,\n",
    "    'idx_to_class': {idx: cls for cls, idx in train_dataset.class_to_idx.items()},\n",
    "    'class_names': class_dict\n",
    "}, 'orchid_species_model.pth')\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== 10. Test Model on New Images ===============\n",
    "def predict_image(image_path, model, class_names):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = test_transforms\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "        \n",
    "        # Get top 5 predictions\n",
    "        top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Test Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    y_pos = np.arange(5)\n",
    "    plt.barh(y_pos, top5_prob.cpu().numpy())\n",
    "    plt.yticks(y_pos, [class_names[train_dataset.classes[idx]] for idx in top5_catid.cpu().numpy()])\n",
    "    plt.xlabel('Probability')\n",
    "    plt.title('Top 5 Predictions')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_example.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Top 5 predictions:\")\n",
    "    for i in range(5):\n",
    "        print(f\"{i+1}. {class_names[train_dataset.classes[top5_catid[i].item()]]} ({top5_prob[i].item():.4f})\")\n",
    "\n",
    "# Test on some images from the test set\n",
    "test_class = train_dataset.classes[0]  # First class\n",
    "test_image_path = os.path.join(test_dir, test_class, os.listdir(os.path.join(test_dir, test_class))[0])\n",
    "predict_image(test_image_path, model, class_dict)\n",
    "\n",
    "print(\"Training and evaluation complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
